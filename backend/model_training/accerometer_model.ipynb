{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.8.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl.metadata (103 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.14.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\user\\anaconda3\\envs\\research_env\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.9/390.3 MB 15.2 MB/s eta 0:00:26\n",
      "    --------------------------------------- 6.0/390.3 MB 19.4 MB/s eta 0:00:20\n",
      "   - -------------------------------------- 11.5/390.3 MB 18.5 MB/s eta 0:00:21\n",
      "   - -------------------------------------- 16.5/390.3 MB 20.0 MB/s eta 0:00:19\n",
      "   -- ------------------------------------- 21.5/390.3 MB 20.9 MB/s eta 0:00:18\n",
      "   -- ------------------------------------- 28.0/390.3 MB 22.8 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 33.3/390.3 MB 23.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 35.9/390.3 MB 22.1 MB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 40.9/390.3 MB 21.8 MB/s eta 0:00:16\n",
      "   ---- ----------------------------------- 45.1/390.3 MB 21.6 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 49.0/390.3 MB 21.5 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 54.5/390.3 MB 21.7 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 58.7/390.3 MB 21.7 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 64.0/390.3 MB 21.8 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 68.2/390.3 MB 21.8 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 72.1/390.3 MB 21.6 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 75.0/390.3 MB 21.2 MB/s eta 0:00:15\n",
      "   ------- -------------------------------- 77.9/390.3 MB 20.7 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 81.8/390.3 MB 20.6 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 86.0/390.3 MB 20.5 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 89.9/390.3 MB 20.4 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 94.6/390.3 MB 20.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 99.4/390.3 MB 20.6 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 100.9/390.3 MB 20.6 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 104.9/390.3 MB 20.0 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 107.0/390.3 MB 19.7 MB/s eta 0:00:15\n",
      "   ---------- ---------------------------- 109.3/390.3 MB 19.3 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 112.5/390.3 MB 19.1 MB/s eta 0:00:15\n",
      "   ----------- --------------------------- 116.7/390.3 MB 19.1 MB/s eta 0:00:15\n",
      "   ------------ -------------------------- 121.4/390.3 MB 19.2 MB/s eta 0:00:14\n",
      "   ------------ -------------------------- 125.3/390.3 MB 19.2 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 130.3/390.3 MB 19.4 MB/s eta 0:00:14\n",
      "   ------------- ------------------------- 135.3/390.3 MB 19.5 MB/s eta 0:00:14\n",
      "   -------------- ------------------------ 141.6/390.3 MB 19.7 MB/s eta 0:00:13\n",
      "   -------------- ------------------------ 147.3/390.3 MB 20.0 MB/s eta 0:00:13\n",
      "   --------------- ----------------------- 150.2/390.3 MB 20.0 MB/s eta 0:00:13\n",
      "   --------------- ----------------------- 155.5/390.3 MB 19.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 159.6/390.3 MB 19.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 164.1/390.3 MB 20.0 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 167.2/390.3 MB 19.8 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 171.2/390.3 MB 19.8 MB/s eta 0:00:12\n",
      "   ----------------- --------------------- 174.3/390.3 MB 19.7 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 177.7/390.3 MB 19.6 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 181.4/390.3 MB 19.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 184.0/390.3 MB 19.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 187.4/390.3 MB 19.4 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 191.1/390.3 MB 19.3 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 194.5/390.3 MB 19.2 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 198.2/390.3 MB 19.2 MB/s eta 0:00:11\n",
      "   -------------------- ------------------ 202.6/390.3 MB 19.2 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 206.0/390.3 MB 19.1 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 210.2/390.3 MB 19.2 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 213.9/390.3 MB 19.1 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 217.3/390.3 MB 19.1 MB/s eta 0:00:10\n",
      "   ---------------------- ---------------- 221.0/390.3 MB 19.0 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 224.4/390.3 MB 19.0 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 227.8/390.3 MB 18.9 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 230.9/390.3 MB 18.9 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 233.8/390.3 MB 18.8 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 236.5/390.3 MB 18.7 MB/s eta 0:00:09\n",
      "   ----------------------- --------------- 239.6/390.3 MB 18.6 MB/s eta 0:00:09\n",
      "   ------------------------ -------------- 242.5/390.3 MB 18.5 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 245.6/390.3 MB 18.4 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 248.5/390.3 MB 18.4 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 251.4/390.3 MB 18.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 255.1/390.3 MB 18.3 MB/s eta 0:00:08\n",
      "   ------------------------- ------------- 257.9/390.3 MB 18.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 261.9/390.3 MB 18.2 MB/s eta 0:00:08\n",
      "   -------------------------- ------------ 265.0/390.3 MB 18.2 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 269.0/390.3 MB 18.3 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 273.4/390.3 MB 18.2 MB/s eta 0:00:07\n",
      "   --------------------------- ----------- 277.9/390.3 MB 18.2 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 281.5/390.3 MB 18.1 MB/s eta 0:00:07\n",
      "   ---------------------------- ---------- 285.7/390.3 MB 18.0 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 289.7/390.3 MB 17.9 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 293.6/390.3 MB 17.8 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 297.8/390.3 MB 17.8 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 301.2/390.3 MB 17.8 MB/s eta 0:00:06\n",
      "   ------------------------------ -------- 304.1/390.3 MB 17.7 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 307.5/390.3 MB 17.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 311.2/390.3 MB 17.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 314.8/390.3 MB 17.6 MB/s eta 0:00:05\n",
      "   ------------------------------- ------- 318.5/390.3 MB 17.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------ 322.4/390.3 MB 17.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 325.8/390.3 MB 17.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 329.8/390.3 MB 17.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 333.4/390.3 MB 17.3 MB/s eta 0:00:04\n",
      "   --------------------------------- ----- 336.9/390.3 MB 17.3 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 340.5/390.3 MB 17.4 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 343.1/390.3 MB 17.3 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 345.8/390.3 MB 17.2 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 347.6/390.3 MB 17.1 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 349.4/390.3 MB 17.0 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 352.1/390.3 MB 16.9 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 354.4/390.3 MB 16.8 MB/s eta 0:00:03\n",
      "   ----------------------------------- --- 357.0/390.3 MB 16.7 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.4/390.3 MB 16.5 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 361.5/390.3 MB 16.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 363.3/390.3 MB 16.4 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 365.2/390.3 MB 16.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ -- 367.8/390.3 MB 16.2 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 370.7/390.3 MB 16.3 MB/s eta 0:00:02\n",
      "   ------------------------------------- - 374.1/390.3 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 377.5/390.3 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  380.6/390.3 MB 16.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  383.8/390.3 MB 16.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  386.9/390.3 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  388.2/390.3 MB 16.1 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 15.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 15.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading pandas-2.2.3-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "   ---------------------------------------- 0.0/11.5 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 1.8/11.5 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.5 MB 8.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.5/11.5 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 7.9/11.5 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.3/11.5 MB 10.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.5/11.5 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 3.1/15.6 MB 18.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 6.8/15.6 MB 16.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.2/15.6 MB 16.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 14.4/15.6 MB 17.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 16.6 MB/s eta 0:00:00\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 3.7/8.0 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/8.0 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 16.6 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 3.7/11.1 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.3/11.1 MB 18.1 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 15.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 14.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.56.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 13.7 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Downloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
      "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 2.6/40.9 MB 12.5 MB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 5.8/40.9 MB 13.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 8.7/40.9 MB 13.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 11.8/40.9 MB 13.7 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 14.4/40.9 MB 13.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 16.8/40.9 MB 13.2 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 19.1/40.9 MB 12.7 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 21.8/40.9 MB 12.6 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 24.4/40.9 MB 12.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 27.0/40.9 MB 12.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 29.4/40.9 MB 12.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 31.7/40.9 MB 12.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 34.1/40.9 MB 12.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 36.7/40.9 MB 12.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 39.1/40.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 40.9/40.9 MB 12.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.70.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 2.4/4.3 MB 13.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 12.9 MB/s eta 0:00:00\n",
      "Downloading h5py-3.13.0-cp312-cp312-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 2.6/3.0 MB 12.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.0/3.0 MB 12.3 MB/s eta 0:00:00\n",
      "Downloading keras-3.8.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 13.2 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 2.9/26.4 MB 14.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 5.2/26.4 MB 13.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 8.1/26.4 MB 13.3 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.7/26.4 MB 12.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 13.4/26.4 MB 12.7 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.7/26.4 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 18.1/26.4 MB 12.4 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 12.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 23.3/26.4 MB 12.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 12.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 12.6 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.29.3-cp310-abi3-win_amd64.whl (434 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------- ----------------- 3.1/5.5 MB 14.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 13.4 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl (102 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.0-cp312-cp312-win_amd64.whl (299 kB)\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, namex, libclang, flatbuffers, wrapt, urllib3, tzdata, threadpoolctl, termcolor, tensorboard-data-server, pyparsing, protobuf, pillow, optree, opt-einsum, numpy, mdurl, MarkupSafe, markdown, kiwisolver, joblib, idna, grpcio, google-pasta, gast, fonttools, cycler, charset-normalizer, certifi, astunparse, absl-py, werkzeug, scipy, requests, pandas, ml-dtypes, markdown-it-py, h5py, contourpy, tensorboard, scikit-learn, rich, matplotlib, keras, tensorflow-intel, tensorflow\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 certifi-2025.1.31 charset-normalizer-3.4.1 contourpy-1.3.1 cycler-0.12.1 flatbuffers-25.2.10 fonttools-4.56.0 gast-0.6.0 google-pasta-0.2.0 grpcio-1.70.0 h5py-3.13.0 idna-3.10 joblib-1.4.2 keras-3.8.0 kiwisolver-1.4.8 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 matplotlib-3.10.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.14.0 pandas-2.2.3 pillow-11.1.0 protobuf-5.29.3 pyparsing-3.2.1 pytz-2025.1 requests-2.32.3 rich-13.9.4 scikit-learn-1.6.1 scipy-1.15.2 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 threadpoolctl-3.5.0 tzdata-2025.1 urllib3-2.3.0 werkzeug-3.1.3 wrapt-1.17.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow pandas numpy matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 2.0.2\n",
      "pandas version: 2.2.3\n",
      "scipy version: 1.15.2\n",
      "scikit-learn version: 1.6.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from scipy.stats import skew, kurtosis, mode\n",
    "\n",
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"pandas version:\", pd.__version__)\n",
    "print(\"scipy version:\", scipy.__version__)\n",
    "print(\"scikit-learn version:\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "data_18_noleak = pd.read_csv('Accelerometer_readings/LO_NL_0.18 LPS_A2.csv')\n",
    "data_noFlow_noleak = pd.read_csv('Accelerometer_readings/LO_NL_ND_A2.csv')\n",
    "data_47_noleak = pd.read_csv('Accelerometer_readings/LO_NL_0.47 LPS_A2.csv')\n",
    "\n",
    "\n",
    "data_18_gasket = pd.read_csv('Accelerometer_readings/LO_GL_0.18 LPS_A2.csv')\n",
    "data_gasket_noFlow = pd.read_csv('Accelerometer_readings/LO_GL_ND_A2.csv')\n",
    "data_47_nd = pd.read_csv('Accelerometer_readings/LO_GL_0.47 LPS_A2.csv')\n",
    "\n",
    "data_18_CC = pd.read_csv('Accelerometer_readings/LO_CC_0.18 LPS_A2.csv')\n",
    "data_CC_noFlow = pd.read_csv('Accelerometer_readings/LO_CC_ND_A2.csv')\n",
    "data_47_nd_CC = pd.read_csv('Accelerometer_readings/LO_CC_0.47 LPS_A2.csv')\n",
    "\n",
    "data_18_OL = pd.read_csv('Accelerometer_readings/LO_OL_0.18 LPS_A2.csv')\n",
    "data_OL_noFlow = pd.read_csv('Accelerometer_readings/LO_OL_ND_A2.csv')\n",
    "data_47_nd_OL = pd.read_csv('Accelerometer_readings/LO_OL_0.47 LPS_A2.csv')\n",
    "# Combine No Leak and Leak data\n",
    "no_leak_data = pd.concat([data_18_noleak , data_noFlow_noleak , data_47_noleak])\n",
    "no_leak_data['Category'] = 'No Leak'\n",
    "\n",
    "gasket_leak_data = pd.concat([data_18_gasket , data_gasket_noFlow , data_47_nd])\n",
    "gasket_leak_data['Category'] = 'Gasket Leak'\n",
    "\n",
    "CC_leak_data = pd.concat([data_18_CC , data_CC_noFlow , data_47_nd_CC])\n",
    "CC_leak_data['Category'] = 'circumferential leak'\n",
    "\n",
    "OL_leak_data = pd.concat([data_18_OL , data_OL_noFlow , data_47_nd_OL])\n",
    "OL_leak_data['Category'] = 'orifice leak'\n",
    "\n",
    "# Combine all data\n",
    "combined_data = pd.concat([no_leak_data ,gasket_leak_data , CC_leak_data , OL_leak_data]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 11100621\n"
     ]
    }
   ],
   "source": [
    "num_rows = combined_data.shape[0]\n",
    "print(f\"Number of rows: {num_rows}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling rate: 305899.97 Hz\n",
      "Time difference between samples: 0.000003 seconds\n",
      "Window size for 0.004 seconds: 1223 rows\n",
      "Processed windows 0 to 9076 of 9076\n",
      "Features extracted and saved to 'features_extracted.csv'\n"
     ]
    }
   ],
   "source": [
    "# Shell 3: Windowing and Feature Extraction (Memory-Efficient with 0.5-Second Windows)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "\n",
    "# Load data with system features from Shell 2\n",
    "\n",
    "\n",
    "# Debug: Check the sampling rate\n",
    "sample_diff = combined_data['Sample'].diff().dropna().mean()\n",
    "sampling_rate = 1 / sample_diff  # Samples per second\n",
    "window_duration_seconds = 0.004  # Desired window duration in seconds\n",
    "window_size = int(window_duration_seconds * sampling_rate)  # Number of rows per 0.5-second window\n",
    "print(f\"Sampling rate: {sampling_rate:.2f} Hz\")\n",
    "print(f\"Time difference between samples: {sample_diff:.6f} seconds\")\n",
    "print(f\"Window size for 0.004 seconds: {window_size} rows\")\n",
    "\n",
    "# Windowing function\n",
    "def extract_windows(df, window_size):\n",
    "    windows = [df.iloc[i:i + window_size] for i in range(0, len(df) - window_size + 1, window_size)]\n",
    "    return windows\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_features_per_window(window):\n",
    "    features = {}\n",
    "    values = window['Value'].values\n",
    "\n",
    "    # Time-Domain Features\n",
    "    features['Mean'] = np.mean(values)\n",
    "    features['Std'] = np.std(values)\n",
    "    features['Min'] = np.min(values)\n",
    "    features['Max'] = np.max(values)\n",
    "    features['Skewness'] = skew(values)\n",
    "    features['Kurtosis'] = kurtosis(values)\n",
    "    features['PeakToPeak'] = np.ptp(values)\n",
    "    features['Median'] = np.median(values)\n",
    "    features['Mode'] = pd.Series(values).mode()[0] if not pd.Series(values).mode().empty else np.nan\n",
    "    features['FirstQuartile'] = np.percentile(values, 25)\n",
    "    features['ThirdQuartile'] = np.percentile(values, 75)\n",
    "    features['RootMeanSquare'] = np.sqrt(np.mean(values ** 2))\n",
    "    features['RootSumSquares'] = np.sqrt(np.sum(values ** 2))\n",
    "    features['PeakToRMS'] = features['PeakToPeak'] / features['RootMeanSquare'] if features['RootMeanSquare'] != 0 else np.nan\n",
    "    features['Variance'] = np.var(values)\n",
    "    features['PeakPosition'] = np.argmax(values)\n",
    "\n",
    "    # Frequency-Domain Features\n",
    "    fft_values = np.abs(np.fft.fft(values))\n",
    "    freqs = np.fft.fftfreq(len(values))\n",
    "    features['FFT_Mean'] = np.mean(fft_values)\n",
    "    features['FFT_Std'] = np.std(fft_values)\n",
    "    features['FFT_Min'] = np.min(fft_values)\n",
    "    features['FFT_Max'] = np.max(fft_values)\n",
    "    features['FFT_Skewness'] = skew(fft_values)\n",
    "    features['FFT_Kurtosis'] = kurtosis(fft_values)\n",
    "    features['FFT_PeakToPeak'] = np.ptp(fft_values)\n",
    "    features['FFT_Median'] = np.median(fft_values)\n",
    "    features['FFT_Mode'] = pd.Series(fft_values).mode()[0] if not pd.Series(fft_values).mode().empty else np.nan\n",
    "    features['FFT_PeakPosition'] = np.argmax(fft_values)\n",
    "    features['MeanFrequency'] = np.mean(freqs)\n",
    "\n",
    "  \n",
    "\n",
    "   \n",
    "    features['Category'] = window['Category'].iloc[0]\n",
    "\n",
    "    return pd.Series(features)\n",
    "\n",
    "# Process data in chunks to avoid MemoryError\n",
    "chunk_size = 10000  # Number of windows to process at a time (adjust based on your RAM)\n",
    "windows = extract_windows(combined_data, window_size)\n",
    "total_windows = len(windows)\n",
    "\n",
    "# Write features incrementally to CSV\n",
    "first_chunk = True\n",
    "for i in range(0, total_windows, chunk_size):\n",
    "    chunk_windows = windows[i:i + chunk_size]\n",
    "    chunk_features = pd.DataFrame([extract_features_per_window(window) for window in chunk_windows])\n",
    "    chunk_features = chunk_features.dropna()  # Drop NaN rows within the chunk\n",
    "    \n",
    "    # Write to CSV: append mode for subsequent chunks, header only for first chunk\n",
    "    if first_chunk:\n",
    "        chunk_features.to_csv('features_extracted.csv', mode='w', index=False)\n",
    "        first_chunk = False\n",
    "    else:\n",
    "        chunk_features.to_csv('features_extracted.csv', mode='a', header=False, index=False)\n",
    "    \n",
    "    print(f\"Processed windows {i} to {min(i + chunk_size, total_windows)} of {total_windows}\")\n",
    "\n",
    "print(\"Features extracted and saved to 'features_extracted.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaler saved successfully!\n",
      "Scaled features and labels saved to 'X_scaled.csv' and 'y_multiclass.csv'\n"
     ]
    }
   ],
   "source": [
    "# Shell 4: Prepare Data for Modeling (with Categorical Encoding)\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# Load features from Shell 3\n",
    "features = pd.read_csv('features_extracted.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X = features.drop(columns=['Category'])\n",
    "y = features['Category']\n",
    "\n",
    "# Feature scaling (only numeric columns)\n",
    "scaler = MinMaxScaler()\n",
    "numeric_columns = X.select_dtypes(include=[np.number]).columns\n",
    "X_scaled_numeric = pd.DataFrame(scaler.fit_transform(X[numeric_columns]), \n",
    "                                columns=numeric_columns)\n",
    "\n",
    "# Save the scaler\n",
    "joblib.dump(scaler, 'Accelerometer_classifiedscaler.pkl')\n",
    "print(\"Scaler saved successfully!\")\n",
    "\n",
    "\n",
    "\n",
    "# Combine scaled numeric and encoded categorical features\n",
    "X_scaled = pd.concat([X_scaled_numeric], axis=1)\n",
    "\n",
    "# Save scaled features and labels\n",
    "X_scaled.to_csv('X_scaled.csv', index=False)\n",
    "y.to_csv('y_multiclass.csv', index=False)\n",
    "print(\"Scaled features and labels saved to 'X_scaled.csv' and 'y_multiclass.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "         Gasket Leak       0.76      0.73      0.75       456\n",
      "             No Leak       0.86      0.74      0.79       454\n",
      "circumferential leak       0.74      0.77      0.75       453\n",
      "        orifice leak       0.77      0.88      0.82       453\n",
      "\n",
      "            accuracy                           0.78      1816\n",
      "           macro avg       0.78      0.78      0.78      1816\n",
      "        weighted avg       0.78      0.78      0.78      1816\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[334   0 122   0]\n",
      " [  0 335   0 119]\n",
      " [106   0 347   0]\n",
      " [  0  54   0 399]]\n",
      "\n",
      "Accuracy: 0.7791850220264317\n"
     ]
    }
   ],
   "source": [
    "# Shell 5: Model Training and Evaluation\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Load scaled features and labels from Shell 4\n",
    "X_scaled = pd.read_csv('X_scaled.csv')\n",
    "y = pd.read_csv('y_multiclass.csv')['Category']  # Assuming 'Category' is the column name\n",
    "\n",
    "# Base estimator\n",
    "base_tree = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_split=5,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Bagging ensemble\n",
    "model = BaggingClassifier(\n",
    "    estimator=base_tree,\n",
    "    n_estimators=600,\n",
    "    max_samples=0.8,\n",
    "    max_features=0.8,\n",
    "    bootstrap=True,\n",
    "    bootstrap_features=False,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'Accerometer_classified_model.pkl')\n",
    "\n",
    "print(\"Model saved successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
